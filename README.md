# ML Time Series API

API de Machine Learning para anÃ¡lisis de series de tiempo usando modelo PerceptrÃ³n. Optimizada para despliegue en Render.com con integraciÃ³n MongoDB.

## ğŸš€ CaracterÃ­sticas

- **FastAPI**: API REST moderna y rÃ¡pida
- **Modelo PerceptrÃ³n**: Optimizado para series de tiempo
- **MongoDB**: IntegraciÃ³n asÃ­ncrona con Motor
- **Docker**: ContainerizaciÃ³n completa
- **Variables de entorno**: ConfiguraciÃ³n segura
- **MÃ©tricas**: MAE, MSE, RMSE incluidas
- **Escalable**: DiseÃ±ado para servicios cloud gratuitos

## ğŸ“ Estructura del Proyecto

```
Proyecto-ml/
â”œâ”€â”€ main.py                 # API principal FastAPI
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ Dockerfile             # ConfiguraciÃ³n Docker
â”œâ”€â”€ docker-compose.yml     # Docker Compose para desarrollo
â”œâ”€â”€ .env.example           # Ejemplo de variables de entorno
â”œâ”€â”€ .gitignore            # Archivos ignorados por Git
â”œâ”€â”€ .dockerignore         # Archivos ignorados por Docker
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ perceptron_model.py # Modelo PerceptrÃ³n para series de tiempo
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ mongodb_client.py   # Cliente MongoDB asÃ­ncrono
â””â”€â”€ README.md              # Esta documentaciÃ³n
```

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el repositorio

```bash
git clone <tu-repositorio>
cd Proyecto-ml
```

### 2. Configurar variables de entorno

Copiar `.env.example` a `.env` y configurar:

```bash
# MongoDB Configuration
MONGODB_URL=mongodb+srv://username:password@cluster.mongodb.net/
MONGODB_DATABASE=tu_base_de_datos

# API Configuration
PORT=8000
ENVIRONMENT=production

# Model Configuration
DEFAULT_WINDOW_SIZE=10
DEFAULT_EPOCHS=100
MODEL_SAVE_PATH=./models/saved_model.pkl
```

### 3. Desarrollo local con Docker

```bash
# Construir y ejecutar
docker-compose up --build

# Solo ejecutar (si ya estÃ¡ construido)
docker-compose up

# Ejecutar en background
docker-compose up -d
```

### 4. Desarrollo local sin Docker

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar API
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸŒ Despliegue en la Nube

### Variables de Entorno Requeridas

Todas las plataformas necesitan estas variables:
```bash
MONGODB_URL=mongodb+srv://user:password@cluster.mongodb.net/
MONGODB_DATABASE=nombre_base_datos
PORT=8000
ENVIRONMENT=production
```

### 1. ğŸš€ **Render.com** (Gratis con limitaciones)

**âœ… Pros:** FÃ¡cil, gratis  
**âŒ Contras:** Se duerme tras 15min inactividad (delay 50s)

```bash
# Build Command
docker build -t ml-api .

# Start Command  
docker run -p $PORT:8000 ml-api
```

1. Conectar repositorio GitHub
2. Seleccionar "Web Service"
3. Configurar variables de entorno
4. Deploy automÃ¡tico

---

### 2. âš¡ **Railway.app** (Recomendado)

**âœ… Pros:** $5/mes gratis, sin sleep, mejor rendimiento  
**âŒ Contras:** Requiere tarjeta de crÃ©dito

```bash
# Instalar Railway CLI
npm install -g @railway/cli

# Login y deploy
railway login
railway project create
railway up
```

**O desde GitHub:**
1. Conectar repositorio en railway.app
2. Configurar variables de entorno
3. Deploy automÃ¡tico

---

### 3. â˜ï¸ **Google Cloud Run** (Escalable)

**âœ… Pros:** $300 iniciales, pay-per-use, profesional  
**âŒ Contras:** MÃ¡s complejo

```bash
# Instalar Google Cloud CLI
gcloud auth login
gcloud config set project TU_PROJECT_ID

# Deploy
gcloud run deploy ml-api \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 8000
```

---

### 4. ğŸŒŠ **Fly.io** (Global)

**âœ… Pros:** 3 apps gratis, servidores globales  
**âŒ Contras:** ConfiguraciÃ³n inicial

```toml
# fly.toml
app = "tu-ml-api"

[build]
  dockerfile = "Dockerfile"

[[services]]
  internal_port = 8000
  protocol = "tcp"

  [[services.ports]]
    handlers = ["http"]
    port = 80

  [[services.ports]]
    handlers = ["tls", "http"]
    port = 443
```

```bash
# Instalar Fly CLI
flyctl launch
flyctl deploy
```

---

### 5. ğŸ”® **DigitalOcean App Platform**

**âœ… Pros:** $200 iniciales, infraestructura sÃ³lida  
**âŒ Contras:** ~$5/mes despuÃ©s de crÃ©ditos

1. Conectar repositorio GitHub
2. Seleccionar "Docker" como build pack
3. Configurar variables de entorno
4. Deploy

---

### 6. âš¡ **Vercel** (Solo APIs rÃ¡pidas)

**âš ï¸ LimitaciÃ³n:** Timeout 10s (no ideal para ML)

```json
// vercel.json
{
  "builds": [
    {
      "src": "main.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "main.py"
    }
  ]
}
```

---

## ğŸ¯ **Recomendaciones por Uso**

| Escenario | Plataforma Recomendada | Motivo |
|-----------|----------------------|---------|
| **Desarrollo/Testing** | Render | Gratis, fÃ¡cil setup |
| **ProducciÃ³n PequeÃ±a** | Railway | Sin sleep, confiable |
| **Startup/Empresa** | Google Cloud Run | Escalable, profesional |
| **App Global** | Fly.io | MÃºltiples regiones |
| **Presupuesto Flexible** | DigitalOcean | Balance precio/calidad |

## âš–ï¸ **Estrategia de Redundancia** (Recomendado)

Para mÃ¡xima disponibilidad, desplegar en 2 plataformas:

```javascript
// Cliente con fallback automÃ¡tico
class MLAPIClient {
  constructor() {
    this.apis = [
      'https://tu-api-railway.up.railway.app',  // Principal
      'https://tu-api-render.onrender.com'      // Backup
    ];
    this.currentAPI = 0;
  }

  async makeRequest(endpoint, data, timeout = 30000) {
    for (let i = 0; i < this.apis.length; i++) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);
        
        const response = await fetch(`${this.apis[this.currentAPI]}${endpoint}`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(data),
          signal: controller.signal
        });

        clearTimeout(timeoutId);
        
        if (response.ok) {
          return await response.json();
        }
      } catch (error) {
        console.log(`API ${this.currentAPI} failed, trying backup...`);
        this.currentAPI = (this.currentAPI + 1) % this.apis.length;
      }
    }
    
    throw new Error('All ML APIs are unavailable');
  }
}
```

## ğŸš¨ **Manejo de Cold Starts**

Si usas plataformas con sleep (Render), implementa:

```javascript
// Keep-alive para evitar cold starts
const keepAPIAlive = async () => {
  try {
    await fetch('https://tu-api.onrender.com/health');
  } catch (error) {
    console.log('API warming up...');
  }
};

// Ping cada 10 minutos
setInterval(keepAPIAlive, 10 * 60 * 1000);
```

## ğŸ“– Uso de la API

### Endpoints Principales

#### 1. Health Check
```bash
GET /health
```

Respuesta:
```json
{
  "status": "healthy",
  "database": "connected",
  "model_loaded": false
}
```

#### 2. Entrenar Modelo
```bash
POST /train
Content-Type: application/json

{
  "collection_name": "mi_coleccion",
  "window_size": 10,
  "epochs": 100
}
```

#### 3. Hacer PredicciÃ³n
```bash
POST /predict
Content-Type: application/json

{
  "data": [
    {
      "timestamp": "2024-01-01T00:00:00Z",
      "value": 100.5
    },
    {
      "timestamp": "2024-01-01T01:00:00Z", 
      "value": 102.3
    }
  ],
  "window_size": 10
}
```

#### 4. InformaciÃ³n del Modelo
```bash
GET /model/info
```

### Formato de Datos MongoDB

Los documentos en MongoDB deben tener la estructura:

```json
{
  "_id": "ObjectId",
  "timestamp": "2024-01-01T00:00:00Z",
  "value": 100.5,
  "additional_features": {
    "sensor_id": "sensor_1",
    "location": "office"
  }
}
```

**Campos requeridos:**
- `value`: Valor numÃ©rico de la serie de tiempo
- `timestamp`: Fecha y hora del punto de datos

## ğŸ”§ Ejemplos de Uso

### Python Client

```python
import requests
import json
from datetime import datetime

# URL de tu API
API_URL = "https://tu-app.onrender.com"

# 1. Verificar salud
response = requests.get(f"{API_URL}/health")
print(response.json())

# 2. Entrenar modelo
train_data = {
    "collection_name": "sensor_data",
    "window_size": 10,
    "epochs": 50
}
response = requests.post(f"{API_URL}/train", json=train_data)
print(response.json())

# 3. Hacer predicciÃ³n
prediction_data = {
    "data": [
        {"timestamp": "2024-01-01T00:00:00Z", "value": 100.0},
        {"timestamp": "2024-01-01T01:00:00Z", "value": 102.0},
        {"timestamp": "2024-01-01T02:00:00Z", "value": 104.0},
        # ... mÃ¡s datos hasta completar window_size
    ],
    "window_size": 10
}
response = requests.post(f"{API_URL}/predict", json=prediction_data)
print(response.json())
```

### JavaScript Client

```javascript
// 1. Entrenar modelo
const trainModel = async () => {
  const response = await fetch('https://tu-app.onrender.com/train', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      collection_name: 'sensor_data',
      window_size: 10,
      epochs: 50
    })
  });
  
  const result = await response.json();
  console.log(result);
};

// 2. Hacer predicciÃ³n
const makePrediction = async (timeSeries) => {
  const response = await fetch('https://tu-app.onrender.com/predict', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      data: timeSeries,
      window_size: 10
    })
  });
  
  const result = await response.json();
  return result.prediction;
};
```

## ğŸ§ª Testing

### Probar endpoints localmente

```bash
# Health check
curl http://localhost:8000/health

# InformaciÃ³n del modelo
curl http://localhost:8000/model/info

# Entrenar (reemplazar con tu colecciÃ³n)
curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"collection_name": "tu_coleccion", "window_size": 10, "epochs": 50}'
```

## ğŸ“Š MÃ©tricas del Modelo

El modelo proporciona las siguientes mÃ©tricas:

- **MAE** (Mean Absolute Error): Error absoluto medio
- **MSE** (Mean Squared Error): Error cuadrÃ¡tico medio  
- **RMSE** (Root Mean Squared Error): RaÃ­z del error cuadrÃ¡tico medio
- **Final Loss**: PÃ©rdida final del entrenamiento
- **Training Samples**: NÃºmero de muestras de entrenamiento

## ğŸ”’ Seguridad

- Variables de entorno para credenciales sensibles
- Usuario no-root en Docker
- Timeouts configurados para MongoDB
- ValidaciÃ³n de datos de entrada
- Logging para auditorÃ­a

## ğŸ› Troubleshooting

### ğŸ”§ Errores Comunes de Desarrollo

#### "Import could not be resolved"
- **Causa:** Normal durante desarrollo sin dependencias instaladas
- **SoluciÃ³n:** Se resuelve automÃ¡ticamente en Docker/producciÃ³n

#### Error de conexiÃ³n MongoDB
```bash
# Verificar conectividad
curl -X GET https://tu-api.com/database/test
```
- Verificar `MONGODB_URL` en variables de entorno
- Asegurar IP en whitelist de MongoDB Atlas  
- Confirmar permisos de usuario (lectura mÃ­nimo)
- Probar conexiÃ³n directa con MongoDB Compass

### ğŸš€ Errores de Despliegue

#### Error de memoria/recursos
```yaml
# SÃ­ntomas: 
# - Timeouts durante entrenamiento
# - Out of memory errors
# - API no responde

# Soluciones:
```
- **Reducir epochs:** `epochs: 20` â†’ `epochs: 10`
- **Window size menor:** `window_size: 10` â†’ `window_size: 5`  
- **Menos datos:** Limitar dataset de entrenamiento
- **Migrar a plataforma** con mÃ¡s recursos (Railway, GCP)

#### API no responde
```bash
# Diagnosticar
curl -v https://tu-api.com/health

# Revisar logs (ejemplo Railway)
railway logs

# Revisar logs (ejemplo Render)  
# Ver dashboard â†’ Logs
```

**Soluciones por plataforma:**
- **Render:** Verificar que no estÃ© en sleep mode
- **Railway:** Revisar variables de entorno
- **Google Cloud:** Verificar quotas y billing
- **Fly.io:** Revisar health checks

#### Docker build fails
```bash
# Error comÃºn: dependencias
# SoluciÃ³n: Verificar requirements.txt

# Error comÃºn: permisos
# SoluciÃ³n: Verificar Dockerfile permisos de usuario

# Error comÃºn: puertos
# SoluciÃ³n: Exponer puerto correcto (8000)
```

### â±ï¸ Problemas de Performance

#### Cold Start lento (>30s)
```javascript
// Implementar pre-calentamiento
const warmupAPI = async () => {
  try {
    await fetch('https://tu-api.com/health', { 
      timeout: 60000 
    });
  } catch (e) {
    console.log('Cold start detected');
  }
};
```

#### Predicciones lentas
- **Verificar:** TamaÃ±o del modelo (window_size)
- **Reducir:** Epochs de entrenamiento
- **Cache:** Implementar cache de predicciones
- **Batch:** Agrupar mÃºltiples predicciones

### ğŸ” Debugging

#### Ver logs en tiempo real
```bash
# Railway
railway logs --tail

# Render  
# Dashboard â†’ Logs tab

# Google Cloud Run
gcloud logging read "resource.type=cloud_run_revision"

# Fly.io
flyctl logs

# DigitalOcean
doctl apps logs <app-id> --tail
```

#### Probar endpoints localmente
```bash
# Health check
curl http://localhost:8000/health

# Test con datos reales
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"data": [...], "window_size": 5}'
```

#### Variables de entorno
```bash
# Verificar que estÃ©n configuradas
curl https://tu-api.com/model/info

# DeberÃ­a mostrar conexiÃ³n DB exitosa
```

## ï¿½ Monitoreo y Alertas

### Health Checks Automatizados
```javascript
// Implementar en tu app principal
const healthMonitor = {
  async checkAPI() {
    try {
      const response = await fetch('https://tu-api.com/health');
      const data = await response.json();
      
      if (data.status !== 'healthy') {
        this.sendAlert('API unhealthy', data);
      }
      
      return data;
    } catch (error) {
      this.sendAlert('API down', error);
      throw error;
    }
  },

  sendAlert(type, details) {
    // Integrar con tu sistema de alertas
    console.error(`ğŸš¨ ${type}:`, details);
  }
};

// Verificar cada 5 minutos
setInterval(() => healthMonitor.checkAPI(), 5 * 60 * 1000);
```

## ğŸ“ Soporte

### 1. ğŸ” DiagnÃ³stico AutomÃ¡tico
```bash
# Script de diagnÃ³stico
curl -s https://tu-api.com/health | jq '.'
curl -s https://tu-api.com/model/info | jq '.'
curl -s https://tu-api.com/database/test | jq '.'
```

### 2. ğŸ“‹ Checklist de Problemas
- [ ] Variables de entorno configuradas
- [ ] MongoDB accesible desde la plataforma  
- [ ] Puerto expuesto correctamente (8000)
- [ ] Dockerfile building sin errores
- [ ] Logs muestran conexiÃ³n DB exitosa
- [ ] Health endpoint responde 200

### 3. ğŸ†˜ EscalaciÃ³n
Si persisten problemas:
1. **Revisar logs especÃ­ficos** de la plataforma
2. **Probar localmente** con Docker
3. **Verificar quotas/lÃ­mites** de la plataforma
4. **Considerar migraciÃ³n** a otra plataforma

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.
